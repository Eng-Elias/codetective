# Tasks and Workflow

## Current Focus: Module 3 Productionization (AAIDC Certificate)

**Objective**: Transform Codetective into a production-ready, enterprise-grade multi-agent system

### Module 3 Requirements Mapping
- ‚úÖ **User Interface**: NiceGUI already implemented
- ‚úÖ **Testing Suite**: **75%+ coverage achieved** (exceeds 70% requirement) - 450+ tests passing
- ‚úÖ **Safety & Security Guardrails**: **Phase 2 Complete** - 3 security modules integrated
- üîÑ **Resilience & Monitoring**: Partial - needs retry logic and advanced monitoring (Phase 3)
- üîÑ **Professional Documentation**: Partial - needs comprehensive docs (Phase 4)

## Module 3 Enhancement Tasks

### Phase 1: Testing Infrastructure (Priority: HIGH) ‚úÖ COMPLETED!
**Goal**: Achieve 70%+ test coverage for core functionality
**Status**: ‚úÖ COMPLETE - **72.28% Coverage Achieved** (290 tests passing)

#### Phase 1A: Test Framework ‚úÖ COMPLETE
- 173 passing tests
- 45.92% coverage baseline
- All infrastructure in place

#### Phase 1B: Coverage Improvement to 70%+ ‚úÖ COMPLETE
**Target**: Reach 70%+ coverage by adding strategic unit tests
**Strategy**: Exclude CLI (integration-heavy), focus on core business logic
**Result**: ‚úÖ **72.28% Coverage Achieved - Exceeded Target!**

#### Task 1.1: Unit Testing Framework Setup ‚úÖ
- ‚úÖ Create `tests/` directory structure with unit, integration, e2e folders
- ‚úÖ Install pytest, pytest-cov, pytest-asyncio, pytest-mock
- ‚úÖ Configure pytest.ini with coverage settings and test markers
- ‚úÖ Create conftest.py with 40+ common fixtures
- ‚úÖ Add Makefile targets for test execution

#### Task 1.2: Agent Unit Tests ‚úÖ
- ‚úÖ `tests/unit/test_semgrep_agent.py` - Test pattern matching, rule parsing, result formatting (14 tests)
- ‚úÖ `tests/unit/test_trivy_agent.py` - Test vulnerability detection, JSON parsing, error handling (13 tests)
- [ ] `tests/unit/test_dynamic_ai_review_agent.py` - Mock Ollama, test prompt generation, response parsing
- ‚úÖ `tests/unit/test_output_agents.py` - CommentAgent & EditAgent tests with backup handling (19 tests)
- ‚úÖ `tests/unit/test_ai_base.py` - Test ChatOllama integration, error handling, response cleaning (21 tests)

#### Task 1.3: Core Component Unit Tests ‚úÖ
- [ ] `tests/unit/test_orchestrator.py` - Test agent coordination, parallel execution, error aggregation
- ‚úÖ `tests/unit/test_config.py` - Test configuration loading, validation, environment variables (17 tests)
- ‚úÖ `tests/unit/test_schemas.py` - Test Pydantic models, serialization, validation (19 tests)
- ‚úÖ `tests/unit/test_base_agent.py` - Test BaseAgent, ScanAgent, OutputAgent (14 tests)

#### Task 1.4: Utility Unit Tests ‚úÖ
- ‚úÖ `tests/unit/test_file_utils.py` - Test file operations, gitignore parsing, path validation (20 tests)
- ‚úÖ `tests/unit/test_git_utils.py` - Mock git commands, test repo detection, file selection (12 tests)
- ‚úÖ `tests/unit/test_process_utils.py` - Test command execution, timeout handling, output capture (14 tests)
- [ ] `tests/unit/test_string_utils.py` - Test string manipulation, sanitization, cleaning
- [ ] `tests/unit/test_system_utils.py` - Test tool availability checks, system compatibility

#### Task 1.4B: Phase 1B Priority Tests (Coverage Push to 70%+) ‚úÖ COMPLETED
**Objective**: Add strategic unit tests to reach 70%+ coverage
**Result**: **72.28% Coverage - Target Exceeded!**

**HIGH-IMPACT TESTS (Big Coverage Gains):**
- ‚úÖ üî¥ **test_orchestrator.py** - COMPLETED (14.83% ‚Üí 79.94%, 27 tests)
  - ‚úÖ Agent initialization and configuration
  - ‚úÖ LangGraph state management
  - ‚úÖ Parallel vs sequential execution modes
  - ‚úÖ Result aggregation across agents
  - ‚úÖ Error handling and recovery
  - ‚úÖ Agent coordination workflows
  
- [ ] üü° **test_dynamic_ai_review_agent.py** - OPTIONAL (15.38% ‚Üí 70%+, for 75%+ coverage)
  - Code review prompt generation
  - AI response parsing and validation
  - Fallback mode handling
  - Issue extraction from responses
  - Severity mapping and categorization
  - ChatOllama integration mocking

- [ ] üü° **Expand test_output_agents.py** - OPTIONAL (58.60% ‚Üí 75%+, for higher coverage)
  - EditAgent fix validation logic
  - Batch file processing edge cases
  - File write operation error handling
  - Backup restoration scenarios
  - Invalid fix detection

**QUICK WIN TESTS (Small Modules, Easy Coverage):**
- ‚úÖ üü¢ **test_string_utils.py** - COMPLETED (20% ‚Üí 96%, 30 tests)
  - ‚úÖ String sanitization functions
  - ‚úÖ Code cleaning utilities
  - ‚úÖ Format conversion helpers
  
- ‚úÖ üü¢ **test_system_utils.py** - COMPLETED (38% ‚Üí 96.63%, 24 tests)
  - ‚úÖ Tool availability detection
  - ‚úÖ Platform-specific checks
  - ‚úÖ Required tools validation
  - ‚úÖ System compatibility checks

**MEDIUM-IMPACT TESTS (Steady Improvements):**
- ‚úÖ üü¢ **Expand test_git_utils.py** - COMPLETED (+17 tests, improved coverage)
  - ‚úÖ Enhanced file selection logic
  - ‚úÖ Tree structure building
  - ‚úÖ Git diff operations
  - ‚úÖ Untracked file handling
  
- ‚úÖ üü¢ **test_prompt_builder.py** - COMPLETED (42% ‚Üí 100%, 41 tests)
  - ‚úÖ Template rendering
  - ‚úÖ Context variable substitution
  - ‚úÖ Structured prompt generation
  - ‚úÖ Issue formatting

**Coverage Achievement**: ‚úÖ **72.28% - Exceeded 70% Target!**

#### Phase 1B Summary:
- **Tests Added**: 117 new tests (173 ‚Üí 290)
- **Coverage Improvement**: +26.36% (45.92% ‚Üí 72.28%)
- **Files Created**: 5 new test files
- **Files Expanded**: 1 test file (git_utils)
- **Execution Time**: ~74 seconds for full test suite

#### Task 1.5: Integration Tests
- [ ] `tests/integration/test_scan_workflow.py` - Test full scan pipeline with real tools
- [ ] `tests/integration/test_fix_workflow.py` - Test complete fix application workflow
- [ ] `tests/integration/test_multi_agent_coordination.py` - Test agent communication and result merging
- [ ] `tests/integration/test_cli_commands.py` - Test CLI command execution and output
- [ ] `tests/integration/test_gui_operations.py` - Test GUI state management and user flows

#### Task 1.6: End-to-End Tests
- [ ] `tests/e2e/test_vulnerable_code_detection.py` - Test detection of real vulnerabilities
- [ ] `tests/e2e/test_automated_fix_application.py` - Test fixing real security issues
- [ ] `tests/e2e/test_git_integration.py` - Test git-aware scanning on real repositories
- [ ] `tests/e2e/test_complete_user_journey.py` - Test scan ‚Üí review ‚Üí fix ‚Üí verify workflow

### Phase 2: Security & Safety Guardrails (Priority: HIGH) ‚úÖ COMPLETED!
**Status**: ‚úÖ **COMPLETE** - Revised for local application architecture
**Goal**: Implement production-grade security for AAIDC Module 3 requirement
**Result**: 3 security modules integrated, 160 security tests, RateLimiter removed (not needed for local app)

#### Task 2.1: Input Validation ‚úÖ
- ‚úÖ Created `codetective/security/input_validator.py` (400+ lines)
  - ‚úÖ Path validation (prevent directory traversal)
  - ‚úÖ File size limits (100MB max, prevent memory exhaustion)
  - ‚úÖ File type validation (40+ code extensions whitelist)
  - ‚úÖ JSON schema validation
  - ‚úÖ Command injection prevention
  - ‚úÖ Integrated into FileUtils.validate_paths()
  - ‚úÖ 65 comprehensive tests

#### Task 2.2: Prompt Injection Protection ‚úÖ
- ‚úÖ Created `codetective/security/prompt_guard.py` (450+ lines)
  - ‚úÖ 20+ prompt injection patterns detection
  - ‚úÖ Content safety filtering for AI inputs/outputs
  - ‚úÖ Token limit enforcement (32K max, prevent context overflow)
  - ‚úÖ Suspicious code pattern detection
  - ‚úÖ Sensitive data filtering (API keys, passwords, tokens)
  - ‚úÖ Integrated into AIAgent.call_ai()
  - ‚úÖ 50 comprehensive tests

#### Task 2.3: Output Filtering & Safety ‚úÖ
- ‚úÖ Created `codetective/security/output_filter.py` (400+ lines)
  - ‚úÖ Filter sensitive information from logs (API keys, tokens, passwords)
  - ‚úÖ Sanitize AI-generated code suggestions
  - ‚úÖ Validate fix outputs (detect malicious patterns)
  - ‚úÖ Content safety checks
  - ‚úÖ Malicious code detection (rm -rf, backdoors, reverse shells)
  - ‚úÖ Dangerous function detection (eval, exec, pickle)
  - ‚úÖ Fix change ratio validation (80% threshold)
  - ‚úÖ 45 comprehensive tests

#### Task 2.4: Rate Limiting & Abuse Prevention ‚ùå REMOVED
- ‚ùå RateLimiter **removed** - Not needed for local application
  - **Reason**: Codetective is a local NiceGUI app with local Ollama
  - **Decision**: No external APIs = no rate limiting needed
  - **Alternative**: System resource monitoring can be added in Phase 3 if needed
  - **Impact**: Simplified architecture, focused on actual security needs

### Phase 3: Multi-LLM Support (Priority: MEDIUM)

#### Task 3.1: LLM Provider Abstraction
- [ ] Create `codetective/llm/` package structure
- [ ] Create `codetective/llm/base_provider.py` - Abstract LLM interface
- [ ] Refactor `ai_base.py` to use provider abstraction
- [ ] Add provider selection to Config

#### Task 3.2: Gemini Integration
- [ ] Create `codetective/llm/gemini_provider.py`
- [ ] Install google-generativeai package
- [ ] Implement authentication and API calls
- [ ] Add configuration options (--gemini-api-key, --gemini-model)
- [ ] Update CLI and GUI for Gemini selection

#### Task 3.3: Grok Integration
- [ ] Create `codetective/llm/grok_provider.py`
- [ ] Integrate xAI API client
- [ ] Implement authentication and API calls
- [ ] Add configuration options (--grok-api-key, --grok-model)
- [ ] Update CLI and GUI for Grok selection

#### Task 3.4: Provider Fallback & Selection
- [ ] Implement automatic provider fallback on failure
- [ ] Add provider availability detection
- [ ] Create provider comparison/benchmarking utility
- [ ] Update documentation with provider setup instructions

### Phase 4: Resilience & Monitoring (Priority: HIGH)

#### Task 4.1: Advanced Retry Logic
- [ ] Create `codetective/resilience/retry_policy.py`
  - Exponential backoff with jitter
  - Configurable retry attempts per agent
  - Circuit breaker pattern for failing services
  - Fallback strategies for each agent type

#### Task 4.2: Enhanced Timeout Handling
- [ ] Update `process_utils.py` with progressive timeout warnings
- [ ] Add per-agent timeout configuration
- [ ] Implement timeout monitoring and metrics
- [ ] Create timeout recovery strategies

#### Task 4.3: Loop Prevention & Iteration Limits
- [ ] Add iteration counters to agent execution
- [ ] Implement max iteration limits in orchestrator
- [ ] Detect infinite loop patterns in LangGraph
- [ ] Add circuit breakers for stuck workflows

#### Task 4.4: Comprehensive Logging System
- [ ] Create `codetective/monitoring/logger.py`
  - Structured JSON logging
  - Log levels: DEBUG, INFO, WARNING, ERROR, CRITICAL
  - Separate log files per component (agents, cli, gui)
  - Log rotation and retention policies
  - Performance metrics logging

#### Task 4.5: Monitoring & Observability
- [ ] Create `codetective/monitoring/metrics.py`
  - Agent execution time tracking
  - Success/failure rate metrics
  - Resource usage monitoring
  - LLM token usage tracking
  - Export metrics in Prometheus format (optional)

#### Task 4.6: Health Checks
- [ ] Create `codetective/monitoring/health.py`
  - Tool availability health checks
  - LLM service health checks
  - System resource health checks
  - Health check CLI command (`codetective health`)
  - Health check API endpoint for GUI

### Phase 5: Professional Documentation (Priority: MEDIUM)

#### Task 5.1: API Documentation
- [ ] Create `docs/api/` directory
- [ ] Document agent interfaces and contracts
- [ ] Create API reference for Python package usage
- [ ] Document LangGraph state schema
- [ ] Add docstring coverage enforcement

#### Task 5.2: Troubleshooting Guide
- [ ] Create `docs/TROUBLESHOOTING.md`
  - Common issues and solutions
  - Agent failure debugging
  - LLM connection issues
  - Performance optimization tips
  - FAQ section

#### Task 5.3: Operations Manual
- [ ] Create `docs/OPERATIONS.md`
  - Production deployment checklist
  - Monitoring setup instructions
  - Log management guidelines
  - Performance tuning guide
  - Backup and recovery procedures

#### Task 5.4: Architecture Documentation
- [ ] Create `docs/ARCHITECTURE.md`
  - System architecture diagrams
  - Component interaction flows
  - Data flow diagrams
  - Security architecture
  - Scaling considerations

#### Task 5.5: Contributing Guide Enhancement
- [ ] Update `CONTRIBUTING.md` with testing requirements
- [ ] Add security reporting guidelines
- [ ] Document development workflow
- [ ] Add code review checklist

### Phase 6: CI/CD & Quality Assurance (Priority: LOW)

#### Task 6.1: GitHub Actions Setup
- [ ] Create `.github/workflows/test.yml` - Run tests on PR
- [ ] Create `.github/workflows/lint.yml` - Code quality checks
- [ ] Create `.github/workflows/security.yml` - Security scanning
- [ ] Create `.github/workflows/release.yml` - Automated releases

#### Task 6.2: Code Quality Tools
- [ ] Add pre-commit hooks configuration
- [ ] Configure bandit for security scanning
- [ ] Add mypy for type checking
- [ ] Configure coverage reporting (Codecov/Coveralls)

## Main Workflows

### CLI Workflow
1. **info** ‚Üí Check system compatibility and tool availability
2. **scan** ‚Üí Execute multi-agent code analysis
3. **fix** ‚Üí Apply automated remediation to identified issues
4. **gui** ‚Üí Launch NiceGUI web interface
5. **health** ‚Üí Check system health and component availability (NEW)

### Agent Orchestration Using LangGraph

```
[Start] ‚Üí [Git-Aware File Selection] ‚Üí [Agent Configuration]
    ‚Üì
[Parallel/Sequential Execution Mode]
    ‚Üì
[SemGrep Agent] [Trivy Agent] [Dynamic AI Review Agent]
    ‚Üì                ‚Üì                    ‚Üì
[Static Analysis] [Security Scan] [AI-Powered Analysis]
    ‚Üì
[Result Aggregation] ‚Üí [JSON Output]
    ‚Üì
[Fix Selection] ‚Üí [Comment Agent] OR [Edit Agent]
    ‚Üì
[Backup Creation] ‚Üí [Apply Changes] ‚Üí [Verification] ‚Üí [End]
```

## File Processing Pipelines

### Scan Pipeline
1. **Git Repository Detection**: Identify git repositories and apply smart file selection
2. **File Selection**: Apply .gitignore patterns and git-tracked file filtering
3. **Input Validation**: Verify file paths and permissions
4. **Ollama Configuration**: Initialize AI agents with custom Ollama settings
5. **Agent Dispatch**: Route files to appropriate scanning agents
6. **Execution Mode**: Run agents in parallel or sequential mode
7. **Result Collection**: Aggregate results from all agents with unified error handling
8. **JSON Serialization**: Format results in standardized JSON structure with metadata

### Fix Pipeline
1. **Result Parsing**: Load and validate scan results JSON
2. **Issue Prioritization**: Sort issues by severity and type
3. **AI-Powered Fix Generation**: Use ChatOllama with structured prompts
4. **Fix Strategy Selection**: Choose between comment or edit agents
5. **Backup Creation**: Create safety backups before modifications
6. **Automated Application**: Apply AI-generated fixes with validation
7. **Status Tracking**: Update issue status (fixed/failed) in results
8. **Verification**: Validate that fixes don't break functionality

## GUI Interaction Flows

### Project Selection Flow
1. Display project path input with validation
2. Detect git repositories and show appropriate file selection
3. Configure scan mode (Full Project, Git Diff Only, Custom File Selection)
4. Configure agents (SemGrep, Trivy, AI Review) with availability indicators
5. Configure Ollama settings (base URL, model) with real-time validation
6. Set advanced options (parallel execution, force AI, max files, timeout)
7. Initiate scanning process with progress tracking

### File Selection Modes
1. **Full Project Scan**: all project files (respecting .gitignore)
2. **Git Diff Only**: Show only modified and new files from git diff
3. **Custom File Selection**: Interactive tree selector with git-aware filtering

### Scan Results Flow
1. Display tabbed interface (SemGrep, Trivy, AI Review)
2. Show results with severity indicators and expandable details
3. Provide issue selection checkboxes for fix application
4. Display scan metrics (duration, file count, agent performance)
5. Enable "Select All" functionality for batch operations

### Fix Application Flow
1. Select fix agent type (comment/edit) with configuration options
2. Configure backup settings (create/keep backups)
3. Display real-time progress during AI-powered fix generation
4. Show fix results with success/failure indicators
5. Display modified files list and fix summary
6. Update scan results to remove successfully fixed issues

## Error Recovery Mechanisms

- **Tool Availability**: Graceful degradation when external tools are missing
- **Ollama Connection**: Intelligent error handling for AI service connectivity
- **Timeout Handling**: Configurable timeouts with user notification
- **Partial Results**: Continue processing even if some agents fail
- **Git Integration**: Fallback to standard file scanning for non-git directories
- **Backup Safety**: Automatic backup creation before applying fixes
- **State Recovery**: Resume operations from intermediate states
- **User Intervention**: Allow manual override of automated decisions
- **AI Error Handling**: Unified error formatting for model-related issues
